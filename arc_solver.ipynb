{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arc_solver.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMhxVdONEBmkOAD+4zw/xBb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GerardJLarkin/ARC/blob/develop/arc_solver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YR9soFKIb0O"
      },
      "source": [
        "# Build a solver function to solve abstraction & reasoning problems from Francois Chollet's Abstraction & Reasoning Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxyJoBA6Ji0I"
      },
      "source": [
        "\r\n",
        "I kept getting errors attempting to import the .json file in the training data as I am currently unable to use my own computer, I have to use my work laptop which does not allow me to install anything other than google on the desktop. I downloaded anaconda but due to restrictions it will not run. I attempted to add the downloads folder (the only folder I can access) to my python file path but still no joy.\r\n",
        "\r\n",
        "import sys\r\n",
        "\r\n",
        "sys.path\r\n",
        "\r\n",
        "sys.path.append(r'C:\\Users\\33271\\Downloads\\PTAI\\ARC\\data\\training' )\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "data_1 = pd.read_json((r\"https://github.com/GerardJLarkin/ARC/tree/develop/data/training/fcc82909.json\"), lines=True, orient='records')\r\n",
        "\r\n",
        "f = open(r\"C:\\Users\\33271\\Downloads\\PTAI\\ARC\\data\\training\\fcc82909.json\", \"r\")\r\n",
        "\r\n",
        "print(f.read())\r\n",
        "\r\n",
        "I therefore have to manually load all datasets I want to try solve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxtrWM-kqOPo"
      },
      "source": [
        "data = {\"train\": [{\"input\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 7, 2, 7, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 7, 2, 7, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"output\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 7, 0, 2, 0, 0, 0, 0, 0, 0, 0], [0, 2, 7, 2, 0, 0, 0, 0, 0, 0, 0, 0], [7, 7, 2, 7, 7, 0, 0, 0, 0, 0, 0, 0], [0, 2, 7, 2, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 7, 0, 2, 0, 2, 0, 7, 0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 2, 7, 2, 0, 0], [0, 0, 0, 0, 0, 0, 7, 7, 2, 7, 7, 0], [0, 0, 0, 0, 0, 0, 0, 2, 7, 2, 0, 0], [0, 0, 0, 0, 0, 0, 2, 0, 7, 0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}, {\"input\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 8, 6, 8, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 8, 6, 8, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"output\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 0, 8, 0, 6, 0, 0, 0, 0, 0, 0], [0, 0, 6, 8, 6, 0, 0, 0, 0, 0, 0, 0], [0, 8, 8, 6, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 6, 8, 6, 0, 0, 0, 0, 0, 0, 0], [0, 6, 0, 8, 0, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 6, 0, 8, 0, 6, 0], [0, 0, 0, 0, 0, 0, 0, 6, 8, 6, 0, 0], [0, 0, 0, 0, 0, 0, 8, 8, 6, 8, 8, 0], [0, 0, 0, 0, 0, 0, 0, 6, 8, 6, 0, 0], [0, 0, 0, 0, 0, 0, 6, 0, 8, 0, 6, 0]]}], \"test\": [{\"input\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 3, 4, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"output\": [[0, 0, 0, 0, 0, 0, 4, 0, 3, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 4, 3, 4, 0, 0], [0, 0, 0, 0, 0, 0, 3, 3, 4, 3, 3, 0], [0, 0, 0, 0, 0, 0, 0, 4, 3, 4, 0, 0], [0, 0, 0, 0, 0, 0, 4, 0, 3, 0, 4, 0], [4, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0], [0, 4, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 4, 3, 3, 0, 0, 0, 0, 0, 0, 0], [0, 4, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}]}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSToB7U66oyF"
      },
      "source": [
        "data1 = {\"train\": [{\"input\": [[2, 0, 0], [0, 2, 0], [0, 0, 2]], \"output\": [[2, 0, 0], [0, 4, 0], [0, 0, 2]]}, {\"input\": [[0, 0, 9, 0, 0, 0, 0, 0], [0, 0, 0, 9, 0, 0, 0, 0], [0, 0, 0, 0, 9, 0, 0, 0], [0, 0, 0, 0, 0, 9, 0, 0], [9, 0, 0, 0, 0, 0, 9, 0], [0, 9, 0, 0, 0, 0, 0, 9], [0, 0, 9, 0, 0, 0, 0, 0], [0, 0, 0, 9, 0, 0, 0, 0]], \"output\": [[0, 0, 9, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 0, 0, 0], [0, 0, 0, 0, 9, 0, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0], [9, 0, 0, 0, 0, 0, 9, 0], [0, 4, 0, 0, 0, 0, 0, 4], [0, 0, 9, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 0, 0, 0]]}, {\"input\": [[0, 0, 3, 0, 0, 0], [0, 0, 0, 3, 0, 0], [0, 0, 0, 0, 3, 0], [3, 0, 0, 0, 0, 3], [0, 3, 0, 0, 0, 0], [0, 0, 3, 0, 0, 0]], \"output\": [[0, 0, 3, 0, 0, 0], [0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 3, 0], [3, 0, 0, 0, 0, 4], [0, 4, 0, 0, 0, 0], [0, 0, 3, 0, 0, 0]]}], \"test\": [{\"input\": [[0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0], [0, 6, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0], [0, 0, 6, 0, 0, 0, 0, 6, 0, 0, 0, 0], [0, 0, 0, 6, 0, 0, 0, 0, 6, 0, 0, 0], [0, 0, 0, 0, 6, 0, 0, 0, 0, 6, 0, 0], [0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 6, 0], [0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 6], [6, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0], [0, 6, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0], [0, 0, 6, 0, 0, 0, 0, 0, 0, 6, 0, 0], [0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 6, 0]], \"output\": [[0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0], [0, 0, 6, 0, 0, 0, 0, 4, 0, 0, 0, 0], [0, 0, 0, 4, 0, 0, 0, 0, 6, 0, 0, 0], [0, 0, 0, 0, 6, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 6, 0], [0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 4], [6, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0], [0, 0, 6, 0, 0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 6, 0]]}]}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B42vGg0L9KH_"
      },
      "source": [
        "data2 = {\"train\": [{\"input\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"output\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 5, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}, {\"input\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"output\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3, 3, 3, 5, 7, 7, 7, 7, 7], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}], \"test\": [{\"input\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9]], \"output\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 4, 4, 4, 4, 5, 8, 8, 8, 8, 8], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [6, 6, 6, 6, 6, 5, 9, 9, 9, 9, 9]]}]}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yGXJjjMJ7r7"
      },
      "source": [
        "The approach I am taking is to describe as accurately as possible the state space of the training input and output arrays.\r\n",
        "Once their descriptions are obtained we compare them and attempt* to elucidate a ruleset that informs how one is transformed into another.\r\n",
        "\r\n",
        "I worked though examples myself and attempted to code my own abstraction and resoning logic into code. This is where the description of each array arose from.\r\n",
        "\r\n",
        "But the description is limited as it does not cover may forms of logic that I used to solve the problems.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVSS2M5j7DIc"
      },
      "source": [
        "# import all required libraries\r\n",
        "import numpy as np\r\n",
        "import collections as cs\r\n",
        "from itertools import groupby\r\n",
        "from collections import defaultdict\r\n",
        "from itertools import groupby, combinations\r\n",
        "from math import hypot\r\n",
        "import networkx as nx"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thymn8snONc0"
      },
      "source": [
        "# define function to get the size of the input array and\r\n",
        "# an output array of the required size\r\n",
        "def size(data):\r\n",
        "    rec_shpe_in = []\r\n",
        "    rec_shpe_out = []\r\n",
        "    for i in data:\r\n",
        "        for j in data[i]:\r\n",
        "            for k, v in j.items():\r\n",
        "                if k == 'input':\r\n",
        "                    ary = np.array(v).shape\r\n",
        "                    rec_shpe_in.append(ary)\r\n",
        "                else:\r\n",
        "                    ary = np.array(v).shape\r\n",
        "                    rec_shpe_out.append(ary)\r\n",
        "\r\n",
        "    return rec_shpe_in, rec_shpe_out\r\n",
        "\r\n",
        "# define function to obtain indexes of each digit in a row/column\r\n",
        "def recur_val_ind(lst, el):\r\n",
        "    index_pos_list = []\r\n",
        "    for i in range(len(lst)):\r\n",
        "        if lst[i] == el:\r\n",
        "            index_pos_list.append(i)\r\n",
        "    return index_pos_list\r\n",
        "\r\n",
        "# define Euclidean distance between two points\r\n",
        "def distance(p1,p2):\r\n",
        "    x1,y1 = p1\r\n",
        "    x2,y2 = p2\r\n",
        "    return hypot(x2 - x1, y2 - y1)\r\n",
        "\r\n",
        "# define function to get data\r\n",
        "def data_array(data, array_type = 'input'):\r\n",
        "    in_shp = []\r\n",
        "    for i in data:\r\n",
        "        for j in data[i]:\r\n",
        "            for k, v in j.items():\r\n",
        "                if k == array_type:\r\n",
        "                    in_shp.append(list(v))\r\n",
        "                else:\r\n",
        "                    pass\r\n",
        "    \r\n",
        "    in_shape = np.array(in_shp)\r\n",
        "\r\n",
        "    return in_shape"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojiKD1b3uGdM"
      },
      "source": [
        "# define function to describe the inidces and groups of the array\r\n",
        "# update array type to input/output depending on requirements\r\n",
        "def ind_grp_descr(data, array_type = 'input'): \r\n",
        "    in_shape = data_array(data, array_type)\r\n",
        "    val_indexes = []\r\n",
        "    dist_indexes = []\r\n",
        "    val_groups = []\r\n",
        "    \r\n",
        "    # get indices of same values in each array, groups of same values\r\n",
        "    for a in range(len(in_shape)):\r\n",
        "        k = in_shape[a]\r\n",
        "        inds = []\r\n",
        "        dists = []\r\n",
        "        vals = np.unique(k)\r\n",
        "        for dig in vals:\r\n",
        "            b, c = np.where(k == dig) # dig here are the digits 0-9\r\n",
        "            locs = list(zip(b, c))\r\n",
        "            inds.append( tuple((dig, locs)) )\r\n",
        "        # create a list of groups of the same values (val, indexes) that are in contact (dist less than sqrt(2))\r\n",
        "        for a in range(len(inds)):\r\n",
        "            j = inds[a][1]\r\n",
        "            l = inds[a][0]\r\n",
        "            n_lst = []\r\n",
        "            k = [i for i in combinations(j,2)]\r\n",
        "            dt = [distance(*combo) for combo in combinations(j,2)]\r\n",
        "            val_dt = list(zip(k, dt))\r\n",
        "            for a in val_dt:\r\n",
        "                if a[1] <= np.sqrt(2):\r\n",
        "                    n_lst.append(a[0])\r\n",
        "                    dists.append( tuple((l, a[0])) ) # l is digit 0-9, a[0] is coordinate pair with small distance\r\n",
        "            # merge/join lists that have common elements\r\n",
        "            # solution taken from: https://stackoverflow.com/questions/42036188/merging-tuples-if-they-have-one-common-element\r\n",
        "            graph = nx.Graph(n_lst)\r\n",
        "            neighbours = list(nx.connected_components(graph))\r\n",
        "            val_groups.append((l, neighbours))\r\n",
        "\r\n",
        "        val_indexes.append(inds)\r\n",
        "        dist_indexes.append(dists)\r\n",
        "\r\n",
        "    return val_indexes, dist_indexes, val_groups"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wJ89uq3Agzb"
      },
      "source": [
        "# define function to describe the frequency of colours in an array\r\n",
        "# update array type to input/output depending on requirements\r\n",
        "def array_vals(data, array_type = 'input'):\r\n",
        "    in_shape = data_array(data, array_type)\r\n",
        "    array_val_freq = []\r\n",
        "\r\n",
        "    # get frequency of each colour in each array\r\n",
        "    for a in range(len(in_shape)):\r\n",
        "        i = in_shape[a]\r\n",
        "        (values, counts) = np.unique(i, return_counts=True)\r\n",
        "        array_vals = list(zip(values, counts))\r\n",
        "        array_vals.sort(key=lambda x:x[1], reverse=True)\r\n",
        "        array_val_freq.append(array_vals)\r\n",
        "\r\n",
        "    return array_val_freq"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNxSh7KdBHfM"
      },
      "source": [
        "# define function to describe the rows of an array\r\n",
        "# update array type to input/output depending on requirements\r\n",
        "def row_descr(data, array_type = 'input'):\r\n",
        "    in_shape = data_array(data, array_type)\r\n",
        "    row_descr = []\r\n",
        "    r_freq_count = []\r\n",
        "    r_seq_descr = []\r\n",
        "\r\n",
        "    ## compare all row elements ##\r\n",
        "    for a in range(len(in_shape)):\r\n",
        "        # get ith array in training data\r\n",
        "        i = in_shape[a]\r\n",
        "        \r\n",
        "        elem_cnt = []       \r\n",
        "        # add freq of elements to element list\r\n",
        "        for ind, row in enumerate(i):\r\n",
        "            elements_count = cs.Counter(row)\r\n",
        "            el_count = dict(elements_count)\r\n",
        "            el_str = tuple(('{}th row'.format(ind), '{}'.format(el_count)))\r\n",
        "            elem_cnt.append(el_str)\r\n",
        "        r_freq_count.append(elem_cnt)\r\n",
        "        \r\n",
        "        row_d = []\r\n",
        "        # iterate through rows and index each row\r\n",
        "        for ind, r in enumerate(i):\r\n",
        "            if all(j == r[0] for j in r):\r\n",
        "                row_d.append( tuple(('{}th row'.format(ind), 'all same')) )\r\n",
        "            elif len(set(r)) == len(r):\r\n",
        "                row_d.append( tuple(('{}th row'.format(ind), 'all diff')) )       \r\n",
        "            else:\r\n",
        "                ind_lst = []\r\n",
        "                set_ind = set(r)\r\n",
        "                for a in set_ind:\r\n",
        "                    if a in r:\r\n",
        "                        indices = recur_val_ind(r, a)\r\n",
        "                        # add 1 to each index and divide by lenght of row to get pattern??\r\n",
        "                        ind_lst.append((a, indices))\r\n",
        "                row_d.append( tuple(('{}th row'.format(ind),ind_lst)) )\r\n",
        "                # can I derive a pattern for each digit in each row?\r\n",
        "        row_descr.append((row_d))\r\n",
        "\r\n",
        "        seq_lst = []\r\n",
        "        # get sequences in each row\r\n",
        "        for ind, row in enumerate(i):\r\n",
        "            seqs = [list(group) for val, group in groupby(row)]\r\n",
        "            seq_str = tuple(('{}th row'.format(ind), '{}'.format(seqs)))\r\n",
        "            seq_lst.append(seq_str)\r\n",
        "        r_seq_descr.append(seq_lst)\r\n",
        "\r\n",
        "    return row_descr, r_freq_count, r_seq_descr"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqHJLGlHBw2Y"
      },
      "source": [
        "# define function to describe the columns of an array\r\n",
        "# update array type to input/output depending on requirements\r\n",
        "def col_descr(data, array_type = 'input'):\r\n",
        "    in_shape = data_array(data, array_type)\r\n",
        "    col_descr = []\r\n",
        "    c_freq_count = [] \r\n",
        "    c_seq_descr = []\r\n",
        "\r\n",
        "    ## compare all column elements\r\n",
        "    for a in range(len(in_shape)):\r\n",
        "        # take single array from array list and transpose\r\n",
        "        i = in_shape[a].T\r\n",
        "\r\n",
        "        elem_cnt = []       \r\n",
        "        # add freq of elements to element list\r\n",
        "        for ind, row in enumerate(i):\r\n",
        "            elements_count = cs.Counter(row)\r\n",
        "            el_count = dict(elements_count)\r\n",
        "            el_str = tuple(('{}th col'.format(ind), '{}'.format(el_count)))\r\n",
        "            elem_cnt.append(el_str)\r\n",
        "        c_freq_count.append(elem_cnt)\r\n",
        "\r\n",
        "        col_d = []\r\n",
        "        # create range from 1 to num of cols\r\n",
        "        for ind, r in enumerate(i):\r\n",
        "            if all(j == r[0] for j in r):\r\n",
        "                col_d.append( tuple(('{}th col'.format(ind), 'all same')) )\r\n",
        "            elif len(set(r)) == len(r):\r\n",
        "                col_d.append( tuple(('{}th col'.format(ind), 'all diff')) )       \r\n",
        "            else:\r\n",
        "                ind_lst = []\r\n",
        "                set_ind = set(r)\r\n",
        "                for a in set_ind:\r\n",
        "                    if a in r:\r\n",
        "                        indices = recur_val_ind(r, a)\r\n",
        "                        # add 1 to each index and divide by lenght of col to get pattern??\r\n",
        "                        ind_lst.append((a, indices))\r\n",
        "                col_d.append( tuple(('{}th col'.format(ind),ind_lst)) )\r\n",
        "                # can I derive a pattern for each digit in each col?\r\n",
        "        col_descr.append((col_d))\r\n",
        "\r\n",
        "        seq_lst = []\r\n",
        "        # get sequences in each row\r\n",
        "        for ind, row in enumerate(i):\r\n",
        "            seqs = [list(group) for val, group in groupby(row)]\r\n",
        "            seq_str = tuple(('{}th col'.format(ind), '{}'.format(seqs)))\r\n",
        "            seq_lst.append(seq_str)\r\n",
        "        c_seq_descr.append(seq_lst)\r\n",
        "\r\n",
        "    return col_descr, c_freq_count, c_seq_descr"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIIViPVZDhqN"
      },
      "source": [
        "# define function to describe the diagonals of an array\r\n",
        "# update array type to input/output depending on requirements\r\n",
        "def diag_descr(data, array_type = 'input'):\r\n",
        "    in_shape = data_array(data, array_type)\r\n",
        "    n_diag_descr = []\r\n",
        "    u_diag_descr = []\r\n",
        "    l_diag_descr = []\r\n",
        "    n_diag_freq_count = []\r\n",
        "    u_diag_freq_count = []\r\n",
        "    l_diag_freq_count = []\r\n",
        "    n_diag_seq = []\r\n",
        "    u_diag_seq = []\r\n",
        "    l_diag_seq = []\r\n",
        "\r\n",
        "    # compare all diagonal elements\r\n",
        "    for a in range(len(in_shape)):\r\n",
        "        k = in_shape[a]\r\n",
        "        rec_width = k.shape[0]\r\n",
        "        rec_depth = k.shape[1]\r\n",
        "\r\n",
        "        n_diag_elem_cnt = []       \r\n",
        "        # add freq of elements to element list\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_offset = np.diagonal(k, offset = i)\r\n",
        "            elements_count = cs.Counter(diag_offset)\r\n",
        "            el_count = dict(elements_count)\r\n",
        "            el_str = tuple(('{}th diag'.format(i), '{}'.format(el_count)))\r\n",
        "            n_diag_elem_cnt.append(el_str)\r\n",
        "        n_diag_freq_count.append(n_diag_elem_cnt)\r\n",
        "\r\n",
        "        u_diag_elem_cnt = []       \r\n",
        "        # add freq of elements to element list\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_up = np.flipud(k)\r\n",
        "            diag_up_offset = np.diagonal(diag_up, offset = i)\r\n",
        "            elements_count = cs.Counter(diag_up_offset)\r\n",
        "            el_count = dict(elements_count)\r\n",
        "            el_str = tuple(('{}th diag'.format(i), '{}'.format(el_count)))\r\n",
        "            u_diag_elem_cnt.append(el_str)\r\n",
        "        u_diag_freq_count.append(u_diag_elem_cnt)\r\n",
        "\r\n",
        "        l_diag_elem_cnt = []       \r\n",
        "        # add freq of elements to element list\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_lr = np.fliplr(k)\r\n",
        "            diag_lr_offset = np.diagonal(diag_lr, offset = i)\r\n",
        "            elements_count = cs.Counter(diag_lr_offset)\r\n",
        "            el_count = dict(elements_count)\r\n",
        "            el_str = tuple(('{}th diag'.format(i), '{}'.format(el_count)))\r\n",
        "            l_diag_elem_cnt.append(el_str)\r\n",
        "        l_diag_freq_count.append(l_diag_elem_cnt)\r\n",
        "\r\n",
        "        diag_n = []\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_offset = np.diagonal(k, offset = i)\r\n",
        "            if all(l == diag_offset[0] for l in diag_offset):\r\n",
        "                diag_n.append( tuple(('{}th diag'.format(i),'all same')) )\r\n",
        "            elif len(set(diag_offset)) == len(diag_offset):\r\n",
        "                diag_n.append( tuple(('{}th diag'.format(i),'all same')) )\r\n",
        "            else:\r\n",
        "                ind_lst = []\r\n",
        "                set_ind = set(diag_offset)\r\n",
        "                for a in set_ind:\r\n",
        "                    if a in diag_offset:\r\n",
        "                        indices = recur_val_ind(diag_offset, a)\r\n",
        "                        # add 1 to each index and divide by lenght of row to get pattern??\r\n",
        "                        ind_lst.append((a, indices))\r\n",
        "                diag_n.append( tuple(('{}th diag'.format(i),ind_lst)) )\r\n",
        "                # can I derive a pattern for each digit in each row?\r\n",
        "        n_diag_descr.append(diag_n)\r\n",
        "\r\n",
        "        diag_u = []\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_up = np.flipud(k)\r\n",
        "            diag_up_offset = np.diagonal(diag_up, offset = i)\r\n",
        "            if all(l == diag_up_offset[0] for l in diag_up_offset):\r\n",
        "                diag_u.append( tuple(('{}th diag'.format(i),'all same')) )\r\n",
        "            elif len(set(diag_up_offset)) == len(diag_up_offset):\r\n",
        "                diag_u.append( tuple(('{}th diag'.format(i),'all same')) )\r\n",
        "            else:\r\n",
        "                ind_lst = []\r\n",
        "                set_ind = set(diag_up_offset)\r\n",
        "                for a in set_ind:\r\n",
        "                    if a in diag_up_offset:\r\n",
        "                        indices = recur_val_ind(diag_up_offset, a)\r\n",
        "                        # add 1 to each index and divide by lenght of row to get pattern??\r\n",
        "                        ind_lst.append((a, indices))\r\n",
        "                diag_u.append( tuple(('{}th diag'.format(i),ind_lst)) )\r\n",
        "                # can I derive a pattern for each digit in each row?\r\n",
        "        u_diag_descr.append(diag_u)\r\n",
        "\r\n",
        "        diag_l = []\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_lr = np.fliplr(k)\r\n",
        "            diag_lr_offset = np.diagonal(diag_lr, offset = i)\r\n",
        "            if all(l == diag_lr_offset[0] for l in diag_lr_offset):\r\n",
        "                diag_l.append( tuple(('{}th diag'.format(i),'all same')) )\r\n",
        "            elif len(set(diag_lr_offset)) == len(diag_lr_offset):\r\n",
        "                diag_l.append( tuple(('{}th diag'.format(i),'all same')) )\r\n",
        "            else:\r\n",
        "                ind_lst = []\r\n",
        "                set_ind = set(diag_lr_offset)\r\n",
        "                for a in set_ind:\r\n",
        "                    if a in diag_lr_offset:\r\n",
        "                        indices = recur_val_ind(diag_lr_offset, a)\r\n",
        "                        # add 1 to each index and divide by lenght of row to get pattern??\r\n",
        "                        ind_lst.append((a, indices))\r\n",
        "                diag_l.append( tuple(('{}th diag'.format(i),ind_lst)) )\r\n",
        "                # can I derive a pattern for each digit in each row?\r\n",
        "        l_diag_descr.append(diag_l)\r\n",
        "\r\n",
        "        n_diag_seq_lst = []\r\n",
        "        # get sequences in each diag norm array\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_offset = np.diagonal(k, offset = i)\r\n",
        "            seqs = [list(group) for val, group in groupby(diag_offset)]\r\n",
        "            seq_str = tuple(('{}th diag'.format(i), '{}'.format(seqs)))\r\n",
        "            n_diag_seq_lst.append(seq_str)\r\n",
        "        n_diag_seq.append(n_diag_seq_lst)\r\n",
        "\r\n",
        "        u_diag_seq_lst = []\r\n",
        "        # get sequences in each diag flip up/down array\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_up = np.flipud(k)\r\n",
        "            diag_offset = np.diagonal(diag_up, offset = i)\r\n",
        "            seqs = [list(group) for val, group in groupby(diag_offset)]\r\n",
        "            seq_str = tuple(('{}th diag'.format(i), '{}'.format(seqs)))\r\n",
        "            u_diag_seq_lst.append(seq_str)\r\n",
        "        u_diag_seq.append(u_diag_seq_lst)\r\n",
        "\r\n",
        "        l_diag_seq_lst = []\r\n",
        "        # get sequences in each diag flip left/right array\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_lr = np.fliplr(k)\r\n",
        "            diag_offset = np.diagonal(diag_lr, offset = i)\r\n",
        "            seqs = [list(group) for val, group in groupby(diag_offset)]\r\n",
        "            seq_str = tuple(('{}th diag'.format(i), '{}'.format(seqs)))\r\n",
        "            l_diag_seq_lst.append(seq_str)\r\n",
        "        l_diag_seq.append(l_diag_seq_lst)\r\n",
        "\r\n",
        "    return n_diag_descr, u_diag_descr, l_diag_descr, n_diag_freq_count, u_diag_freq_count,\r\n",
        "    l_diag_freq_count, n_diag_seq, u_diag_seq, l_diag_seq"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8btw6wWMiMM"
      },
      "source": [
        "Compare input and output arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNSKY_EnLQhM",
        "outputId": "1495fb7d-0f3d-439e-e284-bea4b3c9bd55"
      },
      "source": [
        "ary_size = size(data1)\r\n",
        "in_ary_size = ary_size[0]\r\n",
        "out_ary_size = ary_size[1]\r\n",
        "\r\n",
        "in_ary_colours = array_vals(data1, array_type = 'input')\r\n",
        "print(in_ary_colours)\r\n",
        "out_ary_colours = array_vals(data1, array_type = 'output')\r\n",
        "print(out_ary_colours)\r\n",
        "in_out_size_diff = []\r\n",
        "for i in in_ary_size:\r\n",
        "    for j in out_ary_size:\r\n",
        "        if i == j:\r\n",
        "            for k in in_ary_colours:\r\n",
        "                for l in out_ary_colours:\r\n",
        "                    if len(k) == len(l):\r\n",
        "                        print('Input Colours & Output Colours Same')\r\n",
        "                    else:\r\n",
        "                        pass\r\n",
        "            print('Input Size & Output Size Same')\r\n",
        "        else:\r\n",
        "            diff = distance(i,j)\r\n",
        "            in_out_size_diff.append(diff)\r\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 6), (2, 3)], [(0, 54), (9, 10)], [(0, 29), (3, 7)], [(0, 121), (6, 23)]]\n",
            "[[(0, 6), (2, 2), (4, 1)], [(0, 54), (4, 5), (9, 5)], [(0, 29), (3, 4), (4, 3)], [(0, 121), (6, 12), (4, 11)]]\n",
            "Input Size & Output Size Same\n",
            "Input Size & Output Size Same\n",
            "Input Size & Output Size Same\n",
            "Input Size & Output Size Same\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18Nzlxy_aLg6",
        "outputId": "baf541fb-6947-4ca8-cfcc-d845a9f6fa2e"
      },
      "source": [
        "size(data2)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([(5, 11), (5, 11), (5, 11)], [(5, 11), (5, 11), (5, 11)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    }
  ]
}