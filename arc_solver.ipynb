{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arc_solver.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNIamk8G6BOBFe07yAtdD+f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GerardJLarkin/ARC/blob/develop/arc_solver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YR9soFKIb0O"
      },
      "source": [
        "# Build a solver function to solve abstraction & reasoning problems from Francois Chollet's Abstraction & Reasoning Corpus\r\n",
        "\r\n",
        "Student Name: Gerard Larkin\r\n",
        "\r\n",
        "Student Number: 20235986"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxyJoBA6Ji0I"
      },
      "source": [
        "\r\n",
        "I kept getting errors attempting to import the .json file in the training data as I am currently unable to use my own computer, I have to use my work laptop which does not allow me to install anything other than google on the desktop. I downloaded anaconda but due to restrictions it will not run. I attempted to add the downloads folder (the only folder I can access) to my python file path but still no joy.\r\n",
        "\r\n",
        "import sys\r\n",
        "\r\n",
        "sys.path\r\n",
        "\r\n",
        "sys.path.append(r'C:\\Users\\33271\\Downloads\\PTAI\\ARC\\data\\training' )\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "data_1 = pd.read_json((r\"https://github.com/GerardJLarkin/ARC/tree/develop/data/training/fcc82909.json\"), lines=True, orient='records')\r\n",
        "\r\n",
        "f = open(r\"C:\\Users\\33271\\Downloads\\PTAI\\ARC\\data\\training\\fcc82909.json\", \"r\")\r\n",
        "\r\n",
        "print(f.read())\r\n",
        "\r\n",
        "I therefore have to manually load all datasets I want to try solve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxtrWM-kqOPo"
      },
      "source": [
        "data = {\"train\": [{\"input\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 7, 2, 7, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 7, 2, 7, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"output\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 7, 0, 2, 0, 0, 0, 0, 0, 0, 0], [0, 2, 7, 2, 0, 0, 0, 0, 0, 0, 0, 0], [7, 7, 2, 7, 7, 0, 0, 0, 0, 0, 0, 0], [0, 2, 7, 2, 0, 0, 0, 0, 0, 0, 0, 0], [2, 0, 7, 0, 2, 0, 2, 0, 7, 0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 2, 7, 2, 0, 0], [0, 0, 0, 0, 0, 0, 7, 7, 2, 7, 7, 0], [0, 0, 0, 0, 0, 0, 0, 2, 7, 2, 0, 0], [0, 0, 0, 0, 0, 0, 2, 0, 7, 0, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}, {\"input\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 8, 6, 8, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 8, 6, 8, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"output\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 6, 0, 8, 0, 6, 0, 0, 0, 0, 0, 0], [0, 0, 6, 8, 6, 0, 0, 0, 0, 0, 0, 0], [0, 8, 8, 6, 8, 8, 0, 0, 0, 0, 0, 0], [0, 0, 6, 8, 6, 0, 0, 0, 0, 0, 0, 0], [0, 6, 0, 8, 0, 6, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 6, 0, 8, 0, 6, 0], [0, 0, 0, 0, 0, 0, 0, 6, 8, 6, 0, 0], [0, 0, 0, 0, 0, 0, 8, 8, 6, 8, 8, 0], [0, 0, 0, 0, 0, 0, 0, 6, 8, 6, 0, 0], [0, 0, 0, 0, 0, 0, 6, 0, 8, 0, 6, 0]]}], \"test\": [{\"input\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 3, 4, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 3, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"output\": [[0, 0, 0, 0, 0, 0, 4, 0, 3, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 4, 3, 4, 0, 0], [0, 0, 0, 0, 0, 0, 3, 3, 4, 3, 3, 0], [0, 0, 0, 0, 0, 0, 0, 4, 3, 4, 0, 0], [0, 0, 0, 0, 0, 0, 4, 0, 3, 0, 4, 0], [4, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0], [0, 4, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 4, 3, 3, 0, 0, 0, 0, 0, 0, 0], [0, 4, 3, 4, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 3, 0, 4, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}]}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSToB7U66oyF"
      },
      "source": [
        "data1 = {\"train\": [{\"input\": [[2, 0, 0], [0, 2, 0], [0, 0, 2]], \"output\": [[2, 0, 0], [0, 4, 0], [0, 0, 2]]}, {\"input\": [[0, 0, 9, 0, 0, 0, 0, 0], [0, 0, 0, 9, 0, 0, 0, 0], [0, 0, 0, 0, 9, 0, 0, 0], [0, 0, 0, 0, 0, 9, 0, 0], [9, 0, 0, 0, 0, 0, 9, 0], [0, 9, 0, 0, 0, 0, 0, 9], [0, 0, 9, 0, 0, 0, 0, 0], [0, 0, 0, 9, 0, 0, 0, 0]], \"output\": [[0, 0, 9, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 0, 0, 0], [0, 0, 0, 0, 9, 0, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0], [9, 0, 0, 0, 0, 0, 9, 0], [0, 4, 0, 0, 0, 0, 0, 4], [0, 0, 9, 0, 0, 0, 0, 0], [0, 0, 0, 4, 0, 0, 0, 0]]}, {\"input\": [[0, 0, 3, 0, 0, 0], [0, 0, 0, 3, 0, 0], [0, 0, 0, 0, 3, 0], [3, 0, 0, 0, 0, 3], [0, 3, 0, 0, 0, 0], [0, 0, 3, 0, 0, 0]], \"output\": [[0, 0, 3, 0, 0, 0], [0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 3, 0], [3, 0, 0, 0, 0, 4], [0, 4, 0, 0, 0, 0], [0, 0, 3, 0, 0, 0]]}], \"test\": [{\"input\": [[0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0], [0, 6, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0], [0, 0, 6, 0, 0, 0, 0, 6, 0, 0, 0, 0], [0, 0, 0, 6, 0, 0, 0, 0, 6, 0, 0, 0], [0, 0, 0, 0, 6, 0, 0, 0, 0, 6, 0, 0], [0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 6, 0], [0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 6], [6, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0], [0, 6, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0], [0, 0, 6, 0, 0, 0, 0, 0, 0, 6, 0, 0], [0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 6, 0]], \"output\": [[0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0], [0, 0, 6, 0, 0, 0, 0, 4, 0, 0, 0, 0], [0, 0, 0, 4, 0, 0, 0, 0, 6, 0, 0, 0], [0, 0, 0, 0, 6, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 6, 0], [0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 4], [6, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0], [0, 4, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0], [0, 0, 6, 0, 0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 6, 0]]}]}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B42vGg0L9KH_"
      },
      "source": [
        "data2 = {\"train\": [{\"input\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"output\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 5, 2, 2, 2, 2, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}, {\"input\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], \"output\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3, 3, 3, 3, 3, 5, 7, 7, 7, 7, 7], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}], \"test\": [{\"input\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9]], \"output\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 4, 4, 4, 4, 5, 8, 8, 8, 8, 8], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [6, 6, 6, 6, 6, 5, 9, 9, 9, 9, 9]]}]}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yGXJjjMJ7r7"
      },
      "source": [
        "The approach I am taking is to describe as accurately as possible the state space of the training input and output arrays.\r\n",
        "Once their descriptions are obtained we compare them and attempt* to elucidate a ruleset that informs how one is transformed into another.\r\n",
        "\r\n",
        "I worked though examples myself and attempted to code my own abstraction and resoning logic into code. This is where the description of each array arose from.\r\n",
        "\r\n",
        "But the description is limited as it does not cover may forms of logic that I used to solve the problems.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkx73r7T0Q-6"
      },
      "source": [
        "# Overview of attempted solution\r\n",
        "\r\n",
        "GitHub:: https://github.com/GerardJLarkin/ARC/tree/develop\r\n",
        "\r\n",
        "This algorithm does not solve **ANY** tasks. I went all out to try and build a general solver for all ARC tasks. After reading the Chollet's paper, and reading the discussions on Kaggle (where a public contest for solving ARC was held), I was emoboldened to tackle this assignment in the broadest possible sense. \r\n",
        "\r\n",
        "Chollet describes the current state of AI development saying that approaches to date are limited by the absence of generalisation. In that ML algorithms look at all possible combinations to find a solution or find a min/max in a gradient descent sense within the training data but struggle to find solutions for novel data, slightly different (but in the same domain) from the data the model is trained on. \r\n",
        "\r\n",
        "The aim of this project is to strive for broad generalisation which is the ability of a model to account for data beyond the training set but within the domain of the training set.\r\n",
        "\r\n",
        "He gives an in-depth view of model evaluation criteria. He compares our ability to evaluate a model in the realm of human psychometrics and he ultimately champions that models must be measured with respect to human level abilities.\r\n",
        "\r\n",
        "I was impressed by the distinction between the ability of a broad generalised AI model and the skills which that AI model can display. His description of skill being the crystalized end of the models ability to learn is for me one of the main points of the paper. A broad generalised AI should be able to leanr many skills based on its learning ability. \r\n",
        "\r\n",
        "A final point I found interesting is on priors. What prior knowlege should we allow our model to know in order for it to remain in the broad generalisation category? For humans Chollet describes the different priors we have at various stages of our life (low-level priors, meta-learning priors, high-level knowledge priors). He states that is it the meta-learning priors that are the goal of a truly broad generalised AI and it was with that thought that I attempted to describe the state space for the ARC tasks.\r\n",
        "\r\n",
        "The universe tha encompasses the ARC repository is finite. We have the digits 0-9 (colours) arranged in 1D/2D array's of various sizes. The distribution of the colours in each array is non-uniform and as such does not lend itself to extracting knowable patterns. However it is clear that patterns do exist in each array as otherwise they would be indecipherable to human logic. I therefore tried to create as general a description of each array (state space) and then find causal methods of how you can transform from the input to output array. \r\n",
        "\r\n",
        "I used as few high level libraries as possible. I utilised the numpy, math, collections, itertools (which is phenomenal and I need to learn more about) libraries, and the networkx library that allowed me to create groups of the same colour within each array.\r\n",
        "\r\n",
        "I developed functions that covered basic abstractions like, array size, row, column, and diagonal descriptors. I assesed the symmetry of each array and finally identified the indices of each value in an array along with value groups (values that were less than SQRT(2) distance from each other).\r\n",
        "\r\n",
        "Where I had to call a halt to the project was in developing the ruleset that described the differences in each array and how one transforms to another. Given enough time I believe I would have made a decent effort at building a ruleset and this is a project that I will come back to on my own.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVSS2M5j7DIc"
      },
      "source": [
        "# import all required libraries\r\n",
        "import numpy as np\r\n",
        "import collections as cs\r\n",
        "from itertools import groupby\r\n",
        "from collections import defaultdict\r\n",
        "from itertools import groupby, combinations\r\n",
        "from math import hypot\r\n",
        "import networkx as nx"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thymn8snONc0"
      },
      "source": [
        "# define function to get the size of the input array and\r\n",
        "# an output array of the required size\r\n",
        "def size(data):\r\n",
        "    '''Determines the size of each of the arrays in the input/output\r\n",
        "    sections of the training data in the chosen training data file'''\r\n",
        "    rec_shpe_in = []\r\n",
        "    rec_shpe_out = []\r\n",
        "    for i in data:\r\n",
        "        for j in data[i]:\r\n",
        "            for k, v in j.items():\r\n",
        "                if k == 'input':\r\n",
        "                    ary = np.array(v).shape\r\n",
        "                    rec_shpe_in.append(ary)\r\n",
        "                else:\r\n",
        "                    ary = np.array(v).shape\r\n",
        "                    rec_shpe_out.append(ary)\r\n",
        "\r\n",
        "    return rec_shpe_in, rec_shpe_out\r\n",
        "\r\n",
        "# define function to obtain indexes of each digit in a row/column\r\n",
        "def recur_val_ind(lst, el):\r\n",
        "    '''Function to find the indexes of values in a list'''\r\n",
        "    index_pos_list = []\r\n",
        "    for i in range(len(lst)):\r\n",
        "        if lst[i] == el:\r\n",
        "            index_pos_list.append(i)\r\n",
        "    return index_pos_list\r\n",
        "\r\n",
        "# define Euclidean distance between two points\r\n",
        "def distance(p1,p2):\r\n",
        "    '''Function to calculate the Euclidian distnace between\r\n",
        "    two coordinates in an array'''\r\n",
        "    x1,y1 = p1\r\n",
        "    x2,y2 = p2\r\n",
        "    return hypot(x2 - x1, y2 - y1)\r\n",
        "\r\n",
        "# define function to get data\r\n",
        "def data_array(data, array_type = 'input'):\r\n",
        "    '''Function to get either the input or output data from selected \r\n",
        "    file'''\r\n",
        "    in_shp = []\r\n",
        "    for i in data:\r\n",
        "        for j in data[i]:\r\n",
        "            for k, v in j.items():\r\n",
        "                if k == array_type:\r\n",
        "                    in_shp.append(list(v))\r\n",
        "                else:\r\n",
        "                    pass\r\n",
        "    \r\n",
        "    in_shape = np.array(in_shp)\r\n",
        "\r\n",
        "    return in_shape"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojiKD1b3uGdM"
      },
      "source": [
        "# define function to describe the indices and groups of the array\r\n",
        "# update array type to input/output depending on requirements\r\n",
        "def ind_grp_descr(data, array_type = 'input'): \r\n",
        "    '''Function is split into 2 parts:\r\n",
        "        1. Find indexes for all values in an array\r\n",
        "        2. Find groups of values in an array\r\n",
        "    '''\r\n",
        "    in_shape = data_array(data, array_type = 'input')\r\n",
        "    val_indexes = []\r\n",
        "    val_groups = []\r\n",
        "\r\n",
        "    # get indices of same values in each array, groups of same values\r\n",
        "    for a in range(len(in_shape)):\r\n",
        "        k = in_shape[a]\r\n",
        "        inds = []\r\n",
        "        vals = np.unique(k)\r\n",
        "        for dig in vals:\r\n",
        "            b, c = np.where(k == dig) # dig here are the digits 0-9\r\n",
        "            locs = list(zip(b, c))\r\n",
        "            inds.append( tuple((dig, locs)) )\r\n",
        "\r\n",
        "        # create a list of groups of the same values (val, indexes) that are in contact (dist less than sqrt(2))\r\n",
        "        val_grp = []\r\n",
        "        for a in range(len(inds)):\r\n",
        "            j = inds[a][1]\r\n",
        "            l = inds[a][0]\r\n",
        "            p = [i for i in combinations(j,2)]\r\n",
        "            dt = [distance(*combo) for combo in combinations(j,2)]\r\n",
        "            val_dt = list(zip(p, dt))\r\n",
        "            n_lst = []\r\n",
        "            for a in val_dt:\r\n",
        "                if a[1] <= np.sqrt(2):\r\n",
        "                    n_lst.append(a[0])\r\n",
        "            # merge/join lists that have common elements\r\n",
        "            # solution taken from: https://stackoverflow.com/questions/42036188/merging-tuples-if-they-have-one-common-element\r\n",
        "            graph = nx.Graph(n_lst)\r\n",
        "            neighbours = list(nx.connected_components(graph))\r\n",
        "            val_grp.append((l, neighbours))\r\n",
        "\r\n",
        "        val_groups.append(val_grp)\r\n",
        "        val_indexes.append(inds)\r\n",
        "\r\n",
        "    return val_indexes, val_groups"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wJ89uq3Agzb"
      },
      "source": [
        "# define function to describe the frequency of colours in an array\r\n",
        "# update array type to input/output depending on requirements\r\n",
        "def array_vals(data, array_type = 'input'):\r\n",
        "    '''Function to find the frequncy of a value in an array'''\r\n",
        "    in_shape = data_array(data, array_type)\r\n",
        "    array_val_freq = []\r\n",
        "\r\n",
        "    # get frequency of each colour in each array\r\n",
        "    for a in range(len(in_shape)):\r\n",
        "        i = in_shape[a]\r\n",
        "        (values, counts) = np.unique(i, return_counts=True)\r\n",
        "        array_vals = list(zip(values, counts))\r\n",
        "        array_vals.sort(key=lambda x:x[1], reverse=True)\r\n",
        "        array_val_freq.append(array_vals)\r\n",
        "\r\n",
        "    return array_val_freq"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNxSh7KdBHfM"
      },
      "source": [
        "# define function to describe the rows of an array\r\n",
        "# update array type to input/output depending on requirements\r\n",
        "def row_descr(data, array_type = 'input'):\r\n",
        "    '''Function to describe the row of an array. It is split\r\n",
        "    into 3 parts:\r\n",
        "        1. Row Descriptor: Tells us if every colour in a row is different\r\n",
        "        or the same and if it is different where each different value sits\r\n",
        "        2. Get the frequency of each value in a row\r\n",
        "        3. Gets the different sequences of values in each row'''\r\n",
        "    in_shape = data_array(data, array_type)\r\n",
        "    row_descr = []\r\n",
        "    r_freq_count = []\r\n",
        "    r_seq_descr = []\r\n",
        "\r\n",
        "    ## compare all row elements ##\r\n",
        "    for a in range(len(in_shape)):\r\n",
        "        # get ith array in training data\r\n",
        "        i = in_shape[a]\r\n",
        "        \r\n",
        "        elem_cnt = []       \r\n",
        "        # add freq of elements to element list\r\n",
        "        for ind, row in enumerate(i):\r\n",
        "            elements_count = cs.Counter(row)\r\n",
        "            el_count = dict(elements_count)\r\n",
        "            el_str = tuple(('{}th row'.format(ind), '{}'.format(el_count)))\r\n",
        "            elem_cnt.append(el_str)\r\n",
        "        r_freq_count.append(elem_cnt)\r\n",
        "        \r\n",
        "        row_d = []\r\n",
        "        # iterate through rows and index each row\r\n",
        "        for ind, r in enumerate(i):\r\n",
        "            if all(j == r[0] for j in r):\r\n",
        "                row_d.append( tuple(('{}th row'.format(ind), 'all same')) )\r\n",
        "            elif len(set(r)) == len(r):\r\n",
        "                row_d.append( tuple(('{}th row'.format(ind), 'all diff')) )       \r\n",
        "            else:\r\n",
        "                ind_lst = []\r\n",
        "                set_ind = set(r)\r\n",
        "                for a in set_ind:\r\n",
        "                    if a in r:\r\n",
        "                        indices = recur_val_ind(r, a)\r\n",
        "                        # add 1 to each index and divide by lenght of row to get pattern??\r\n",
        "                        ind_lst.append((a, indices))\r\n",
        "                row_d.append( tuple(('{}th row'.format(ind),ind_lst)) )\r\n",
        "                # can I derive a pattern for each digit in each row?\r\n",
        "        row_descr.append((row_d))\r\n",
        "\r\n",
        "        seq_lst = []\r\n",
        "        # get sequences in each row\r\n",
        "        for ind, row in enumerate(i):\r\n",
        "            seqs = [list(group) for val, group in groupby(row)]\r\n",
        "            seq_str = tuple(('{}th row'.format(ind), '{}'.format(seqs)))\r\n",
        "            seq_lst.append(seq_str)\r\n",
        "        r_seq_descr.append(seq_lst)\r\n",
        "\r\n",
        "    return row_descr, r_freq_count, r_seq_descr"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqHJLGlHBw2Y"
      },
      "source": [
        "# define function to describe the columns of an array\r\n",
        "# update array type to input/output depending on requirements\r\n",
        "def col_descr(data, array_type = 'input'):\r\n",
        "    '''Function to describe the column of an array. It is split\r\n",
        "    into 3 parts:\r\n",
        "        1. Column Descriptor: Tells us if every colour in a column is different\r\n",
        "        or the same and if it is different where each different value sits\r\n",
        "        2. Get the frequency of each value in a column\r\n",
        "        3. Gets the different sequences of values in each column'''\r\n",
        "    in_shape = data_array(data, array_type)\r\n",
        "    col_descr = []\r\n",
        "    c_freq_count = [] \r\n",
        "    c_seq_descr = []\r\n",
        "\r\n",
        "    ## compare all column elements\r\n",
        "    for a in range(len(in_shape)):\r\n",
        "        # take single array from array list and transpose\r\n",
        "        i = in_shape[a].T\r\n",
        "\r\n",
        "        elem_cnt = []       \r\n",
        "        # add freq of elements to element list\r\n",
        "        for ind, row in enumerate(i):\r\n",
        "            elements_count = cs.Counter(row)\r\n",
        "            el_count = dict(elements_count)\r\n",
        "            el_str = tuple(('{}th col'.format(ind), '{}'.format(el_count)))\r\n",
        "            elem_cnt.append(el_str)\r\n",
        "        c_freq_count.append(elem_cnt)\r\n",
        "\r\n",
        "        col_d = []\r\n",
        "        # create range from 1 to num of cols\r\n",
        "        for ind, r in enumerate(i):\r\n",
        "            if all(j == r[0] for j in r):\r\n",
        "                col_d.append( tuple(('{}th col'.format(ind), 'all same')) )\r\n",
        "            elif len(set(r)) == len(r):\r\n",
        "                col_d.append( tuple(('{}th col'.format(ind), 'all diff')) )       \r\n",
        "            else:\r\n",
        "                ind_lst = []\r\n",
        "                set_ind = set(r)\r\n",
        "                for a in set_ind:\r\n",
        "                    if a in r:\r\n",
        "                        indices = recur_val_ind(r, a)\r\n",
        "                        # add 1 to each index and divide by lenght of col to get pattern??\r\n",
        "                        ind_lst.append((a, indices))\r\n",
        "                col_d.append( tuple(('{}th col'.format(ind),ind_lst)) )\r\n",
        "                # can I derive a pattern for each digit in each col?\r\n",
        "        col_descr.append((col_d))\r\n",
        "\r\n",
        "        seq_lst = []\r\n",
        "        # get sequences in each row\r\n",
        "        for ind, row in enumerate(i):\r\n",
        "            seqs = [list(group) for val, group in groupby(row)]\r\n",
        "            seq_str = tuple(('{}th col'.format(ind), '{}'.format(seqs)))\r\n",
        "            seq_lst.append(seq_str)\r\n",
        "        c_seq_descr.append(seq_lst)\r\n",
        "\r\n",
        "    return col_descr, c_freq_count, c_seq_descr"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIIViPVZDhqN"
      },
      "source": [
        "# define function to describe the diagonals of an array\r\n",
        "# update array type to input/output depending on requirements\r\n",
        "def diag_descr(data, array_type = 'input'):\r\n",
        "    '''Function to describe the diagonals of an array. It is split\r\n",
        "    into 3x3 parts. Each part represents a specific type of diagonal:\r\n",
        "    - Normal (from top left to botton right)\r\n",
        "    - Flip on horizontal (from bottom left to top right)\r\n",
        "    - Flip on vertical (from bottom right to top left)\r\n",
        "        1. Diag Descriptor: Tells us if every colour in a diagonal is different\r\n",
        "        or the same and if it is different where each different value sits\r\n",
        "        2. Get the frequency of each value in a diagonal\r\n",
        "        3. Gets the different sequences of values in each diagonal\r\n",
        "    '''\r\n",
        "    in_shape = data_array(data, array_type)\r\n",
        "    n_diag_descr = []\r\n",
        "    u_diag_descr = []\r\n",
        "    l_diag_descr = []\r\n",
        "    n_diag_freq_count = []\r\n",
        "    u_diag_freq_count = []\r\n",
        "    l_diag_freq_count = []\r\n",
        "    n_diag_seq = []\r\n",
        "    u_diag_seq = []\r\n",
        "    l_diag_seq = []\r\n",
        "\r\n",
        "    # compare all diagonal elements\r\n",
        "    for a in range(len(in_shape)):\r\n",
        "        k = in_shape[a]\r\n",
        "        rec_width = k.shape[0]\r\n",
        "        rec_depth = k.shape[1]\r\n",
        "\r\n",
        "        n_diag_elem_cnt = []       \r\n",
        "        # add freq of elements to element list\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_offset = np.diagonal(k, offset = i)\r\n",
        "            elements_count = cs.Counter(diag_offset)\r\n",
        "            el_count = dict(elements_count)\r\n",
        "            el_str = tuple(('{}th diag'.format(i), '{}'.format(el_count)))\r\n",
        "            n_diag_elem_cnt.append(el_str)\r\n",
        "        n_diag_freq_count.append(n_diag_elem_cnt)\r\n",
        "\r\n",
        "        u_diag_elem_cnt = []       \r\n",
        "        # add freq of elements to element list\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_up = np.flipud(k)\r\n",
        "            diag_up_offset = np.diagonal(diag_up, offset = i)\r\n",
        "            elements_count = cs.Counter(diag_up_offset)\r\n",
        "            el_count = dict(elements_count)\r\n",
        "            el_str = tuple(('{}th diag'.format(i), '{}'.format(el_count)))\r\n",
        "            u_diag_elem_cnt.append(el_str)\r\n",
        "        u_diag_freq_count.append(u_diag_elem_cnt)\r\n",
        "\r\n",
        "        l_diag_elem_cnt = []       \r\n",
        "        # add freq of elements to element list\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_lr = np.fliplr(k)\r\n",
        "            diag_lr_offset = np.diagonal(diag_lr, offset = i)\r\n",
        "            elements_count = cs.Counter(diag_lr_offset)\r\n",
        "            el_count = dict(elements_count)\r\n",
        "            el_str = tuple(('{}th diag'.format(i), '{}'.format(el_count)))\r\n",
        "            l_diag_elem_cnt.append(el_str)\r\n",
        "        l_diag_freq_count.append(l_diag_elem_cnt)\r\n",
        "\r\n",
        "        diag_n = []\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_offset = np.diagonal(k, offset = i)\r\n",
        "            if all(l == diag_offset[0] for l in diag_offset):\r\n",
        "                diag_n.append( tuple(('{}th diag'.format(i),'all same')) )\r\n",
        "            elif len(set(diag_offset)) == len(diag_offset):\r\n",
        "                diag_n.append( tuple(('{}th diag'.format(i),'all same')) )\r\n",
        "            else:\r\n",
        "                ind_lst = []\r\n",
        "                set_ind = set(diag_offset)\r\n",
        "                for a in set_ind:\r\n",
        "                    if a in diag_offset:\r\n",
        "                        indices = recur_val_ind(diag_offset, a)\r\n",
        "                        # add 1 to each index and divide by lenght of row to get pattern??\r\n",
        "                        ind_lst.append((a, indices))\r\n",
        "                diag_n.append( tuple(('{}th diag'.format(i),ind_lst)) )\r\n",
        "                # can I derive a pattern for each digit in each row?\r\n",
        "        n_diag_descr.append(diag_n)\r\n",
        "\r\n",
        "        diag_u = []\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_up = np.flipud(k)\r\n",
        "            diag_up_offset = np.diagonal(diag_up, offset = i)\r\n",
        "            if all(l == diag_up_offset[0] for l in diag_up_offset):\r\n",
        "                diag_u.append( tuple(('{}th diag'.format(i),'all same')) )\r\n",
        "            elif len(set(diag_up_offset)) == len(diag_up_offset):\r\n",
        "                diag_u.append( tuple(('{}th diag'.format(i),'all same')) )\r\n",
        "            else:\r\n",
        "                ind_lst = []\r\n",
        "                set_ind = set(diag_up_offset)\r\n",
        "                for a in set_ind:\r\n",
        "                    if a in diag_up_offset:\r\n",
        "                        indices = recur_val_ind(diag_up_offset, a)\r\n",
        "                        # add 1 to each index and divide by lenght of row to get pattern??\r\n",
        "                        ind_lst.append((a, indices))\r\n",
        "                diag_u.append( tuple(('{}th diag'.format(i),ind_lst)) )\r\n",
        "                # can I derive a pattern for each digit in each row?\r\n",
        "        u_diag_descr.append(diag_u)\r\n",
        "\r\n",
        "        diag_l = []\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_lr = np.fliplr(k)\r\n",
        "            diag_lr_offset = np.diagonal(diag_lr, offset = i)\r\n",
        "            if all(l == diag_lr_offset[0] for l in diag_lr_offset):\r\n",
        "                diag_l.append( tuple(('{}th diag'.format(i),'all same')) )\r\n",
        "            elif len(set(diag_lr_offset)) == len(diag_lr_offset):\r\n",
        "                diag_l.append( tuple(('{}th diag'.format(i),'all same')) )\r\n",
        "            else:\r\n",
        "                ind_lst = []\r\n",
        "                set_ind = set(diag_lr_offset)\r\n",
        "                for a in set_ind:\r\n",
        "                    if a in diag_lr_offset:\r\n",
        "                        indices = recur_val_ind(diag_lr_offset, a)\r\n",
        "                        # add 1 to each index and divide by lenght of row to get pattern??\r\n",
        "                        ind_lst.append((a, indices))\r\n",
        "                diag_l.append( tuple(('{}th diag'.format(i),ind_lst)) )\r\n",
        "                # can I derive a pattern for each digit in each row?\r\n",
        "        l_diag_descr.append(diag_l)\r\n",
        "\r\n",
        "        n_diag_seq_lst = []\r\n",
        "        # get sequences in each diag norm array\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_offset = np.diagonal(k, offset = i)\r\n",
        "            seqs = [list(group) for val, group in groupby(diag_offset)]\r\n",
        "            seq_str = tuple(('{}th diag'.format(i), '{}'.format(seqs)))\r\n",
        "            n_diag_seq_lst.append(seq_str)\r\n",
        "        n_diag_seq.append(n_diag_seq_lst)\r\n",
        "\r\n",
        "        u_diag_seq_lst = []\r\n",
        "        # get sequences in each diag flip up/down array\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_up = np.flipud(k)\r\n",
        "            diag_offset = np.diagonal(diag_up, offset = i)\r\n",
        "            seqs = [list(group) for val, group in groupby(diag_offset)]\r\n",
        "            seq_str = tuple(('{}th diag'.format(i), '{}'.format(seqs)))\r\n",
        "            u_diag_seq_lst.append(seq_str)\r\n",
        "        u_diag_seq.append(u_diag_seq_lst)\r\n",
        "\r\n",
        "        l_diag_seq_lst = []\r\n",
        "        # get sequences in each diag flip left/right array\r\n",
        "        for i in range(rec_width):\r\n",
        "            diag_lr = np.fliplr(k)\r\n",
        "            diag_offset = np.diagonal(diag_lr, offset = i)\r\n",
        "            seqs = [list(group) for val, group in groupby(diag_offset)]\r\n",
        "            seq_str = tuple(('{}th diag'.format(i), '{}'.format(seqs)))\r\n",
        "            l_diag_seq_lst.append(seq_str)\r\n",
        "        l_diag_seq.append(l_diag_seq_lst)\r\n",
        "\r\n",
        "    return n_diag_descr, u_diag_descr, l_diag_descr, n_diag_freq_count, u_diag_freq_count,\r\n",
        "    l_diag_freq_count, n_diag_seq, u_diag_seq, l_diag_seq"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX930XDUrPrq"
      },
      "source": [
        "# define function to determine symmetry of array\r\n",
        "def array_sym(data, array_type = 'input'):\r\n",
        "    '''Function to describe the symmetry of an array. It is split\r\n",
        "    into 3 parts.\r\n",
        "        1. Horizontal: Checks if symmetrical along the horizontal mid-split\r\n",
        "        2. Vertical: Checks if symmetrical along the vertical mid-split\r\n",
        "        3. Diagonal: Checks if symmetrical along the diagonal split\r\n",
        "    '''\r\n",
        "    in_shape = data_array(data, array_type)\r\n",
        "    # empty list to ensure no empty list is returned on output\r\n",
        "    empty_list = []\r\n",
        "    # split on horizontal access (will work if width is divisible by 2)\r\n",
        "    h_sym = []\r\n",
        "    # split on vertical axis (will work if height is divisible by 2)\r\n",
        "    v_sym = []\r\n",
        "    # check diagonal symmetry\r\n",
        "    d_sym = []\r\n",
        "\r\n",
        "    for a in range(len(in_shape)):\r\n",
        "        i = in_shape[a]\r\n",
        "        x = np.array(i)\r\n",
        "        # check if width is even number to split along vertical\r\n",
        "        if x.shape[1] % 2 == 0:\r\n",
        "            split_arys = np.vsplit(x, 2)\r\n",
        "            rot_ary = np.rot90(split_arys[0],2)\r\n",
        "            if np.array_equal(rot_ary, split_arys[1]) == True:\r\n",
        "                v_sym.append('{}th array is symmetric along vertical'.format(a))\r\n",
        "            else:\r\n",
        "                v_sym.append('{}th array is not symmetric along vertical'.format(a))\r\n",
        "        else:\r\n",
        "            v_sym.append('{}th array odd number of columns'.format(a))\r\n",
        "        # check if can be split along horizontal axis\r\n",
        "        if x.shape[0] % 2 == 0:\r\n",
        "            split_arys = np.hsplit(x, 2)\r\n",
        "            rot_ary = np.rot90(split_arys[0], 2)\r\n",
        "            if np.array_equal(rot_ary, split_arys[1]) == True:\r\n",
        "                h_sym.append('{}th array is symmentric along horizontal'.format(a))\r\n",
        "            else:\r\n",
        "                h_sym.append('{}th array is not symmentric along horizontal'.format(a))\r\n",
        "        else:\r\n",
        "            h_sym.append('{}th array odd number of rows'.format(a))\r\n",
        "        # check if can be split along diagonal axis\r\n",
        "        if x.shape[0] == x.shape[1]:\r\n",
        "            rot_ary = np.rot90(x, 2)\r\n",
        "            if np.array_equal(rot_ary, x) == True:\r\n",
        "                d_sym.append('{}th array is symmetric along diagonal top left to bottom right'.format(a))\r\n",
        "            else:\r\n",
        "                d_sym.append('{}th array is not symmetric along diagonal top left to bottom right'.format(a))\r\n",
        "            flip_ary = np.flipud(x)\r\n",
        "            rot_flip_ary = np.rot90(flip_ary, 2)\r\n",
        "            if np.array_equal(flip_ary, rot_flip_ary) == True:\r\n",
        "                d_sym.append('{}th array is symmentric along diagonal bottom left to top right'.format(a))\r\n",
        "            else:\r\n",
        "                d_sym.append('{}th array is not symmetric along diagonal bottom left to top right'.format(a))\r\n",
        "        else:\r\n",
        "            if x.shape[0] > x.shape[1]:\r\n",
        "                d_sym.append('{}th array more rows than columns'.format(a))\r\n",
        "            else:\r\n",
        "                d_sym.append('{}th aray more columns than rows'.format(a))\r\n",
        "        \r\n",
        "    return h_sym, v_sym, d_sym"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8btw6wWMiMM"
      },
      "source": [
        "*Attempt to develop ruleset to determine differences between input and output AND how to transform from input to output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNSKY_EnLQhM",
        "outputId": "4e19a5f3-52b0-4063-ee4e-3b113d1bac93"
      },
      "source": [
        "# get sizes of input and output arrays and how they differ\r\n",
        "ary_size = size(data2)\r\n",
        "in_ary_size = ary_size[0]\r\n",
        "out_ary_size = ary_size[1]\r\n",
        "# assume number of output arrays match number of input arrays\r\n",
        "in_out_size = []\r\n",
        "for i, j in zip(in_ary_size, out_ary_size):\r\n",
        "    row_diff = []\r\n",
        "    col_diff = []\r\n",
        "    # check if array sizes are equal for input and output\r\n",
        "    if i == j:\r\n",
        "        in_out_size.append('in/out same size')\r\n",
        "    else:\r\n",
        "        if i.shape[0] > j.shape[0]:\r\n",
        "            if (i.shape[0] - j.shape[0]) > 0:\r\n",
        "                row_diff.append('out rows smaller by {} cols'.format((i.shape[0] - j.shape[0])))\r\n",
        "            else:\r\n",
        "                pass\r\n",
        "        else:\r\n",
        "            if (j.shape[0] - i.shape[0]) > 0:\r\n",
        "                row_diff.append('out rows larger by {} cols'.format((j.shape[0] - i.shape[0])))\r\n",
        "            else:\r\n",
        "                pass\r\n",
        "        if i.shape[1] > j.shape[1]:\r\n",
        "            if (i.shape[1] - j.shape[1]) > 0:\r\n",
        "                col_diff.append('out cols smaller by {} cols'.format((i.shape[1] - j.shape[1])))\r\n",
        "            else:\r\n",
        "                pass\r\n",
        "        else:\r\n",
        "            if (j.shape[1] - i.shape[1]) > 0:\r\n",
        "                col_diff.append('out cols larger by {} cols'.format((j.shape[1] - i.shape[1])))\r\n",
        "            else:\r\n",
        "                pass\r\n",
        "    \r\n",
        "    if len(row_diff) > 0:\r\n",
        "        in_out_size.append(row_diff)\r\n",
        "    if len(col_diff) > 0:\r\n",
        "        in_out_size.append(col_diff)\r\n",
        "\r\n",
        "# get colours in input array\r\n",
        "in_ary_colours = array_vals(data2, array_type = 'input')\r\n",
        "in_digits = []\r\n",
        "for i in in_ary_colours:\r\n",
        "    in_digs = []\r\n",
        "    for j in i:\r\n",
        "        in_digs.append(j[0])\r\n",
        "    in_digits.append(in_digs)\r\n",
        "\r\n",
        "# get colours in output array\r\n",
        "out_ary_colours = array_vals(data2, array_type = 'output')\r\n",
        "out_digits = []\r\n",
        "for i in out_ary_colours:\r\n",
        "    out_digs = []\r\n",
        "    for j in i:\r\n",
        "        out_digs.append(j[0])\r\n",
        "    out_digits.append(out_digs)\r\n",
        "\r\n",
        "# create output to describe differences between in and out array\r\n",
        "in_out_colours = []\r\n",
        "# check number of colours in input and output arrays (zip not used as num of colours can be different)\r\n",
        "for i, j in zip(in_digits, out_digits):\r\n",
        "    # checks if the same amount of colours are in each array\r\n",
        "    if len(i) == len(j):\r\n",
        "        colours = []\r\n",
        "        for a, b in zip(i, j):\r\n",
        "            # checks if the same colour is in each array, if not the 'new' colour in the output array is returned\r\n",
        "            # but not sure if this is accurate\r\n",
        "            if a == b:\r\n",
        "                colours.append('{} same in/out'.format(a))\r\n",
        "            else:\r\n",
        "                colours.append('{} new out'.format(b))\r\n",
        "        in_out_colours.append(colours)\r\n",
        "    # if number of colours in each array are different\r\n",
        "    else:\r\n",
        "        same_colours = list(set(i).intersection(set(j)))\r\n",
        "        cols = []\r\n",
        "        for a in same_colours:\r\n",
        "            if len(same_colours) > 0:\r\n",
        "                cols.append('{} same in/out'.format(a))\r\n",
        "            else:\r\n",
        "                pass\r\n",
        "        diff_colours_in = list(set(i).difference(set(j)))\r\n",
        "        for a in diff_colours_in:\r\n",
        "            if len(diff_colours_in) > 0:\r\n",
        "                cols.append('{} in colour only'.format(a))\r\n",
        "            else:\r\n",
        "                pass\r\n",
        "        diff_colours_out = list(set(j).difference(set(i)))\r\n",
        "        for a in diff_colours_out:\r\n",
        "            if len(diff_colours_out) > 0:\r\n",
        "                cols.append('{} out colour only'.format(a))\r\n",
        "    \r\n",
        "    in_out_colours.append(cols)\r\n",
        "\r\n",
        "# get indices of all values in both arrays and find how coordinates differ and by how much\r\n",
        "# so we can transform from one to another\r\n",
        "indices_in = (ind_grp_descr(data2, array_type = 'input'))[0]\r\n",
        "indices_out = (ind_grp_descr(data2, array_type = 'output'))[0]\r\n",
        "\r\n",
        "in_array_colours = []\r\n",
        "for a in range(len(indices_in)):\r\n",
        "    i = indices_in[a]\r\n",
        "    colours = []\r\n",
        "    for j in i:\r\n",
        "        colours.append(j[0])\r\n",
        "    in_array_colours.append(colours)\r\n",
        "\r\n",
        "out_array_colours = []\r\n",
        "for a in range(len(indices_out)):\r\n",
        "    i = indices_out[a]\r\n",
        "    colours = []\r\n",
        "    for j in i:\r\n",
        "        colours.append(j[0])\r\n",
        "    out_array_colours.append(colours)\r\n",
        "\r\n",
        "print(in_array_colours)\r\n",
        "print(out_array_colours)\r\n",
        "\r\n",
        "# if the colours in the input array are the same colours in the outut array then \r\n",
        "# we need to find where the indices differ and create some way of adding/subtracting to changed colours\r\n",
        "not_same_colours = [item for item in in_array_colours if item not in out_array_colours]\r\n",
        "if len(not_same_colours) == 0:\r\n",
        "    in_colour_inds = []\r\n",
        "    for a in range(len(indices_in)):\r\n",
        "        i = indices_in[a]\r\n",
        "        inds = []\r\n",
        "        for j in i:\r\n",
        "            inds.append(j[1])\r\n",
        "        in_colour_inds.append(inds)\r\n",
        "\r\n",
        "print(in_colour_inds)\r\n",
        "#print(in_out_colours)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 1, 2], [0, 3, 7], [0, 4, 6, 8, 9]]\n",
            "[[0, 1, 2], [0, 3, 7], [0, 4, 6, 8, 9]]\n",
            "[[[(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (2, 10), (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9), (3, 10), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (4, 10)], [(1, 0)], [(1, 10)]], [[(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (1, 10), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (2, 10), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9), (4, 10)], [(3, 0)], [(3, 10)]], [[(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), (0, 9), (0, 10), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8), (1, 9), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (2, 9), (2, 10), (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (3, 6), (3, 7), (3, 8), (3, 9), (3, 10), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (4, 7), (4, 8), (4, 9)], [(1, 0)], [(4, 0)], [(1, 10)], [(4, 10)]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18Nzlxy_aLg6",
        "outputId": "1a84ad17-248d-4dcc-f8ea-5fc1f6c84dba"
      },
      "source": [
        "size(data2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([(5, 11), (5, 11), (5, 11)], [(5, 11), (5, 11), (5, 11)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWOspVfpF4BW",
        "outputId": "364f302e-91ff-49a5-be47-fa65311598a0"
      },
      "source": [
        "op = ind_grp_descr(data1, array_type = 'input')\r\n",
        "#op[0] # contains indices all arrays\r\n",
        "#op[0][0] # contains first array\r\n",
        "#op[0][0][0] # contains first digit of first array\r\n",
        "op[0][0][0][1] # contains indices of first digit of first array"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1), (0, 2), (1, 0), (1, 2), (2, 0), (2, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}